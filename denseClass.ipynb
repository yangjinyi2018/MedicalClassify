{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = 'nodule'\n",
    "val_img_path = 'valNodule'\n",
    "label_path = 'trainVal.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvDictReader(path):\n",
    "    with open(path) as rf:\n",
    "        reader = csv.reader(rf)\n",
    "        items = list(reader)\n",
    "    dict = {}\n",
    "    for line in items:\n",
    "        dict[line[0] + '.npz'] = int(line[1])\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, img_path, label_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.label_path = label_path\n",
    "        self.transform = transform\n",
    "        self.img = os.listdir(img_path)# img是一个list\n",
    "        self.labelDict = csvDictReader(label_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_index = self.img[index]\n",
    "        img_path = os.path.join(self.img_path, img_index)\n",
    "        img_voxel = np.load(img_path)['voxel']\n",
    "        img_mask = np.load(img_path)['seg']\n",
    "        #final_img = torch.from_numpy(img_voxel * img_mask * 0.8 + img_voxel * 0.2)[34:66, 34:66, 34:66] / 255\n",
    "        final_img = torch.from_numpy(img_voxel * img_mask)[34:66, 34:66, 34:66] / 255\n",
    "        final_img = torch.unsqueeze(final_img, 0)\n",
    "        label = self.labelDict[img_index]\n",
    "        \n",
    "        return final_img.float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = myDataset(train_img_path, label_path)\n",
    "val_dataset = myDataset(val_img_path, label_path)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)\n",
    "    \n",
    "class GlobalAvgPool3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool3d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool3d(x, kernel_size=x.size()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    blk = nn.Sequential(nn.BatchNorm3d(in_channels),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "    return blk\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, in_channels, out_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        net = []\n",
    "        for i in range(num_convs):\n",
    "            in_c = in_channels + i * out_channels\n",
    "            net.append(conv_block(in_c, out_channels))\n",
    "        self.net = nn.ModuleList(net)\n",
    "        self.out_channels = in_channels + num_convs * out_channels\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X\n",
    "\n",
    "def transition_block(in_channels, out_channels):\n",
    "    blk = nn.Sequential(\n",
    "        nn.BatchNorm3d(in_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size=1),\n",
    "        nn.AvgPool3d(kernel_size=2, stride=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.BatchNorm3d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "num_channels, growth_rate = 16, 32 # 当前的通道数\n",
    "num_convs_in_dense_blocks = [4, 4, 4]\n",
    "\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    DB = DenseBlock(num_convs, num_channels, growth_rate)\n",
    "    net.add_module(\"DenseBlock_%d\" % i, DB)\n",
    "    # 上⼀个DenseBlock的输出通道数\n",
    "    num_channels = DB.out_channels\n",
    "    # 在DenseBlock之间加⼊过渡层，通道数减半\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        net.add_module(\"transition_block_%d\" % i, transition_block(num_channels, num_channels // 2))\n",
    "        num_channels = num_channels // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_module(\"BN\", nn.BatchNorm3d(num_channels))\n",
    "net.add_module(\"relu\", nn.ReLU())\n",
    "net.add_module(\"global_avg_pool\", GlobalAvgPool3d()) \n",
    "net.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(num_channels, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,183,054 total parameters.\n",
      "1,183,054 training parameters.\n"
     ]
    }
   ],
   "source": [
    "# Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = 0.005\n",
    "lr2 = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    # 对loss函数进行混合，criterion是crossEntropy函数\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:05<00:00,  6.19s/it]\n",
      "100%|██████████| 30/30 [03:09<00:00,  6.33s/it]\n",
      "100%|██████████| 30/30 [03:04<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:04<00:00,  6.14s/it]\n",
      "100%|██████████| 30/30 [03:13<00:00,  6.44s/it]\n",
      "100%|██████████| 30/30 [03:11<00:00,  6.40s/it]\n",
      "100%|██████████| 30/30 [03:10<00:00,  6.34s/it]\n",
      "100%|██████████| 30/30 [03:07<00:00,  6.26s/it]\n",
      "100%|██████████| 30/30 [03:06<00:00,  6.20s/it]\n",
      "100%|██████████| 30/30 [03:07<00:00,  6.24s/it]\n",
      "100%|██████████| 30/30 [03:05<00:00,  6.19s/it]\n",
      "100%|██████████| 30/30 [03:04<00:00,  6.13s/it]\n",
      "100%|██████████| 30/30 [03:02<00:00,  6.07s/it]\n",
      "100%|██████████| 30/30 [03:03<00:00,  6.13s/it]\n",
      "100%|██████████| 30/30 [03:06<00:00,  6.22s/it]\n",
      "100%|██████████| 30/30 [03:05<00:00,  6.19s/it]\n",
      "100%|██████████| 30/30 [03:07<00:00,  6.26s/it]\n",
      "100%|██████████| 30/30 [03:07<00:00,  6.26s/it]\n",
      "100%|██████████| 30/30 [03:13<00:00,  6.47s/it]\n",
      "100%|██████████| 30/30 [03:18<00:00,  6.62s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        \n",
    "        \n",
    "        images, targets_a, targets_b, lam = mixup_data(images, labels, 1)    # 对数据集进行mixup操作\n",
    "        \n",
    "        labels_hat = net(images)\n",
    "        #l =  criterion(labels_hat, labels).sum()\n",
    "        l = mixup_criterion(criterion, labels_hat, targets_a, targets_b, lam)    #对loss#函数进行mixup操作\n",
    "        \n",
    "        if epoch<=4:\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=lr1)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=lr2)\n",
    "        \n",
    "        optimizer.zero_grad()# reset gradient\n",
    "        l.backward()\n",
    "        optimizer.step()# update parameters of net\n",
    "        \n",
    "        train_l_sum += l.item()\n",
    "        train_acc_sum += (labels_hat.argmax(dim=1) == labels).sum().item()\n",
    "        n += labels.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/117 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/117 [00:00<00:13,  8.42it/s]\u001b[A/home/yangjinyi2000/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in float_scalars\n",
      "\n",
      "  2%|▏         | 2/117 [00:00<00:14,  8.10it/s]\u001b[A\n",
      "  3%|▎         | 3/117 [00:00<00:13,  8.28it/s]\u001b[A\n",
      "  3%|▎         | 4/117 [00:00<00:14,  7.92it/s]\u001b[A\n",
      "  4%|▍         | 5/117 [00:00<00:13,  8.08it/s]\u001b[A\n",
      "  5%|▌         | 6/117 [00:00<00:14,  7.83it/s]\u001b[A\n",
      "  6%|▌         | 7/117 [00:00<00:13,  8.13it/s]\u001b[A\n",
      "  7%|▋         | 8/117 [00:01<00:14,  7.57it/s]\u001b[A\n",
      "  8%|▊         | 9/117 [00:01<00:14,  7.34it/s]\u001b[A\n",
      "  9%|▊         | 10/117 [00:01<00:14,  7.32it/s]\u001b[A\n",
      "  9%|▉         | 11/117 [00:01<00:14,  7.23it/s]\u001b[A\n",
      " 10%|█         | 12/117 [00:01<00:13,  7.58it/s]\u001b[A\n",
      " 11%|█         | 13/117 [00:01<00:13,  7.53it/s]\u001b[A\n",
      " 12%|█▏        | 14/117 [00:01<00:13,  7.64it/s]\u001b[A\n",
      " 13%|█▎        | 15/117 [00:02<00:14,  6.97it/s]\u001b[A\n",
      " 14%|█▎        | 16/117 [00:02<00:14,  7.03it/s]\u001b[A\n",
      " 15%|█▍        | 17/117 [00:02<00:14,  6.92it/s]\u001b[A\n",
      " 15%|█▌        | 18/117 [00:02<00:13,  7.24it/s]\u001b[A\n",
      " 16%|█▌        | 19/117 [00:02<00:13,  7.26it/s]\u001b[A\n",
      " 17%|█▋        | 20/117 [00:02<00:12,  7.51it/s]\u001b[A\n",
      " 18%|█▊        | 21/117 [00:02<00:12,  7.41it/s]\u001b[A\n",
      " 19%|█▉        | 22/117 [00:02<00:12,  7.70it/s]\u001b[A\n",
      " 20%|█▉        | 23/117 [00:03<00:12,  7.68it/s]\u001b[A\n",
      " 21%|██        | 24/117 [00:03<00:11,  7.99it/s]\u001b[A\n",
      " 21%|██▏       | 25/117 [00:03<00:12,  7.44it/s]\u001b[A\n",
      " 22%|██▏       | 26/117 [00:03<00:11,  7.62it/s]\u001b[A\n",
      " 23%|██▎       | 27/117 [00:03<00:12,  7.47it/s]\u001b[A\n",
      " 24%|██▍       | 28/117 [00:03<00:11,  7.86it/s]\u001b[A\n",
      " 25%|██▍       | 29/117 [00:03<00:11,  7.69it/s]\u001b[A\n",
      " 26%|██▌       | 30/117 [00:03<00:10,  7.94it/s]\u001b[A\n",
      " 26%|██▋       | 31/117 [00:04<00:11,  7.35it/s]\u001b[A\n",
      " 27%|██▋       | 32/117 [00:04<00:11,  7.51it/s]\u001b[A\n",
      " 28%|██▊       | 33/117 [00:04<00:11,  7.35it/s]\u001b[A\n",
      " 29%|██▉       | 34/117 [00:04<00:10,  7.80it/s]\u001b[A\n",
      " 30%|██▉       | 35/117 [00:04<00:10,  7.61it/s]\u001b[A\n",
      " 31%|███       | 36/117 [00:04<00:10,  7.91it/s]\u001b[A\n",
      " 32%|███▏      | 37/117 [00:04<00:10,  7.75it/s]\u001b[A\n",
      " 32%|███▏      | 38/117 [00:05<00:09,  8.03it/s]\u001b[A\n",
      " 33%|███▎      | 39/117 [00:05<00:10,  7.76it/s]\u001b[A\n",
      " 34%|███▍      | 40/117 [00:05<00:09,  8.04it/s]\u001b[A\n",
      " 35%|███▌      | 41/117 [00:05<00:09,  7.83it/s]\u001b[A\n",
      " 36%|███▌      | 42/117 [00:05<00:09,  8.12it/s]\u001b[A\n",
      " 37%|███▋      | 43/117 [00:05<00:09,  7.86it/s]\u001b[A\n",
      " 38%|███▊      | 44/117 [00:05<00:09,  8.07it/s]\u001b[A\n",
      " 38%|███▊      | 45/117 [00:05<00:09,  7.79it/s]\u001b[A\n",
      " 39%|███▉      | 46/117 [00:06<00:09,  7.76it/s]\u001b[A\n",
      " 40%|████      | 47/117 [00:06<00:09,  7.01it/s]\u001b[A\n",
      " 41%|████      | 48/117 [00:06<00:09,  7.46it/s]\u001b[A\n",
      " 42%|████▏     | 49/117 [00:06<00:09,  7.09it/s]\u001b[A\n",
      " 43%|████▎     | 50/117 [00:06<00:09,  7.20it/s]\u001b[A\n",
      " 44%|████▎     | 51/117 [00:06<00:09,  7.10it/s]\u001b[A\n",
      " 44%|████▍     | 52/117 [00:06<00:09,  7.09it/s]\u001b[A\n",
      " 45%|████▌     | 53/117 [00:07<00:09,  6.86it/s]\u001b[A\n",
      " 46%|████▌     | 54/117 [00:07<00:08,  7.11it/s]\u001b[A\n",
      " 47%|████▋     | 55/117 [00:07<00:08,  6.90it/s]\u001b[A\n",
      " 48%|████▊     | 56/117 [00:07<00:08,  6.86it/s]\u001b[A\n",
      " 49%|████▊     | 57/117 [00:07<00:08,  6.97it/s]\u001b[A\n",
      " 50%|████▉     | 58/117 [00:07<00:07,  7.39it/s]\u001b[A\n",
      " 50%|█████     | 59/117 [00:07<00:07,  7.33it/s]\u001b[A\n",
      " 51%|█████▏    | 60/117 [00:07<00:07,  7.65it/s]\u001b[A\n",
      " 52%|█████▏    | 61/117 [00:08<00:07,  7.40it/s]\u001b[A\n",
      " 53%|█████▎    | 62/117 [00:08<00:07,  7.80it/s]\u001b[A\n",
      " 54%|█████▍    | 63/117 [00:08<00:07,  7.65it/s]\u001b[A\n",
      " 55%|█████▍    | 64/117 [00:08<00:06,  7.88it/s]\u001b[A\n",
      " 56%|█████▌    | 65/117 [00:08<00:06,  7.67it/s]\u001b[A\n",
      " 56%|█████▋    | 66/117 [00:08<00:06,  7.86it/s]\u001b[A\n",
      " 57%|█████▋    | 67/117 [00:08<00:06,  7.63it/s]\u001b[A\n",
      " 58%|█████▊    | 68/117 [00:09<00:06,  7.57it/s]\u001b[A\n",
      " 59%|█████▉    | 69/117 [00:09<00:06,  7.45it/s]\u001b[A\n",
      " 60%|█████▉    | 70/117 [00:09<00:06,  7.75it/s]\u001b[A\n",
      " 61%|██████    | 71/117 [00:09<00:06,  7.56it/s]\u001b[A\n",
      " 62%|██████▏   | 72/117 [00:09<00:05,  7.54it/s]\u001b[A\n",
      " 62%|██████▏   | 73/117 [00:09<00:05,  7.47it/s]\u001b[A\n",
      " 63%|██████▎   | 74/117 [00:09<00:05,  7.79it/s]\u001b[A\n",
      " 64%|██████▍   | 75/117 [00:09<00:05,  7.65it/s]\u001b[A\n",
      " 65%|██████▍   | 76/117 [00:10<00:05,  7.92it/s]\u001b[A\n",
      " 66%|██████▌   | 77/117 [00:10<00:05,  7.69it/s]\u001b[A\n",
      " 67%|██████▋   | 78/117 [00:10<00:04,  7.94it/s]\u001b[A\n",
      " 68%|██████▊   | 79/117 [00:10<00:04,  7.79it/s]\u001b[A\n",
      " 68%|██████▊   | 80/117 [00:10<00:04,  8.10it/s]\u001b[A\n",
      " 69%|██████▉   | 81/117 [00:10<00:04,  7.82it/s]\u001b[A\n",
      " 70%|███████   | 82/117 [00:10<00:04,  7.63it/s]\u001b[A\n",
      " 71%|███████   | 83/117 [00:10<00:04,  7.54it/s]\u001b[A\n",
      " 72%|███████▏  | 84/117 [00:11<00:04,  7.15it/s]\u001b[A\n",
      " 73%|███████▎  | 85/117 [00:11<00:04,  7.15it/s]\u001b[A\n",
      " 74%|███████▎  | 86/117 [00:11<00:04,  7.46it/s]\u001b[A\n",
      " 74%|███████▍  | 87/117 [00:11<00:04,  7.06it/s]\u001b[A\n",
      " 75%|███████▌  | 88/117 [00:11<00:04,  6.72it/s]\u001b[A\n",
      " 76%|███████▌  | 89/117 [00:11<00:04,  6.91it/s]\u001b[A\n",
      " 77%|███████▋  | 90/117 [00:11<00:03,  7.35it/s]\u001b[A\n",
      " 78%|███████▊  | 91/117 [00:12<00:03,  7.14it/s]\u001b[A\n",
      " 79%|███████▊  | 92/117 [00:12<00:03,  6.96it/s]\u001b[A\n",
      " 79%|███████▉  | 93/117 [00:12<00:03,  7.00it/s]\u001b[A\n",
      " 80%|████████  | 94/117 [00:12<00:03,  7.30it/s]\u001b[A\n",
      " 81%|████████  | 95/117 [00:12<00:03,  6.93it/s]\u001b[A\n",
      " 82%|████████▏ | 96/117 [00:12<00:02,  7.04it/s]\u001b[A\n",
      " 83%|████████▎ | 97/117 [00:12<00:02,  7.08it/s]\u001b[A\n",
      " 84%|████████▍ | 98/117 [00:13<00:02,  7.35it/s]\u001b[A\n",
      " 85%|████████▍ | 99/117 [00:13<00:02,  6.77it/s]\u001b[A\n",
      " 85%|████████▌ | 100/117 [00:13<00:02,  7.07it/s]\u001b[A\n",
      " 86%|████████▋ | 101/117 [00:13<00:02,  7.19it/s]\u001b[A\n",
      " 87%|████████▋ | 102/117 [00:13<00:02,  7.19it/s]\u001b[A\n",
      " 88%|████████▊ | 103/117 [00:13<00:02,  6.81it/s]\u001b[A\n",
      " 89%|████████▉ | 104/117 [00:13<00:01,  7.21it/s]\u001b[A\n",
      " 90%|████████▉ | 105/117 [00:14<00:01,  7.24it/s]\u001b[A\n",
      " 91%|█████████ | 106/117 [00:14<00:01,  7.28it/s]\u001b[A\n",
      " 91%|█████████▏| 107/117 [00:14<00:01,  7.04it/s]\u001b[A\n",
      " 92%|█████████▏| 108/117 [00:14<00:01,  7.34it/s]\u001b[A\n",
      " 93%|█████████▎| 109/117 [00:14<00:01,  6.86it/s]\u001b[A\n",
      " 94%|█████████▍| 110/117 [00:14<00:00,  7.11it/s]\u001b[A\n",
      " 95%|█████████▍| 111/117 [00:14<00:00,  6.84it/s]\u001b[A\n",
      " 96%|█████████▌| 112/117 [00:15<00:00,  6.74it/s]\u001b[A\n",
      " 97%|█████████▋| 113/117 [00:15<00:00,  6.83it/s]\u001b[A\n",
      " 97%|█████████▋| 114/117 [00:15<00:00,  6.68it/s]\u001b[A\n",
      " 98%|█████████▊| 115/117 [00:15<00:00,  6.61it/s]\u001b[A\n",
      " 99%|█████████▉| 116/117 [00:15<00:00,  6.89it/s]\u001b[A\n",
      "100%|██████████| 117/117 [00:15<00:00,  7.38it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "prediction = np.zeros(117)\n",
    "i = 0\n",
    "for times in tqdm(range(0, 117)):\n",
    "    while not os.path.exists( 'test/candidate'+ str(i+1) + '.npz'):\n",
    "        i = i + 1\n",
    "    tmp = np.load('test/candidate' + str(i+1) + '.npz')\n",
    "    i = i + 1\n",
    "    img_voxel = tmp['voxel']\n",
    "    img_mask = tmp['seg']\n",
    "    x = torch.from_numpy(img_voxel * img_mask * 0.8 + img_voxel * 0.2)[34:66, 34:66, 34:66] / 255\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    x = x.float()\n",
    "\n",
    "    net.eval()\n",
    "    y_hat = net(x)\n",
    "    arr = y_hat.detach().numpy()[0]\n",
    "    prediction[times] = np.exp(arr[1])/(np.exp(arr[0]) + np.exp(arr[1]))\n",
    "    net.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
